{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Pre-Trained Model for BERT (Load Fine-Tuned BERT-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Resi Sujiwo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Downloading Pre-Trained Model for BERT (Load Fine-Tuned BERT-large)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Jakarta server backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "from ast import literal_eval\n",
    "\n",
    "# Question Translation Library\n",
    "import translators as ts\n",
    "import translators.server as tss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     '' Hingga saat ini BINUS masih belum menyedia...\n",
      "1     '' Pengajuan pemindahan program dapat dilakua...\n",
      "2    \"Proses pemindahan program dapat melalui beber...\n",
      "3     '' Cara mengajukan pemindahan lokasi kampus m...\n",
      "4     '' Syarat mengajukan pindah lokasi kuliah ole...\n",
      "5     '' Mahasiswa dapat memilih lebih dari 1 progr...\n",
      "6    \"Calon Mahasiswa yang mengambil single degree ...\n",
      "7    \"Syarat Pendidikan terbagi menjadi 2 yaitu yan...\n",
      "Name: paragraphs, dtype: object\n",
      "  Hingga saat ini BINUS masih belum menyediakan jalur transfer pendaftaran.    Pengajuan pemindahan program dapat dilakuakn dengan dengan mengirimkan email permohonan pindah jurusan ke infobinus@binus.edu lalu akan diberikan formulir pindah program, setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.  \"Proses pemindahan program dapat melalui beberapa proses berikut: 1.Proses pindah program akan dikenakan biaya administrasi sebesar Rp 3.000.000 (tiga juta rupiah) apabila: Permohonan pindah program diajukan setelah tanggal 31 Juli 2023 dan/atau. Permohonan pindah program yang dilakukan untuk kedua kalinya dan atas permohonan pindah program sebelumnya telah disetujui oleh BINUS UNIVERSITY. 2.Batas waktu pengajuan permohonan pindah program adalah sampai dengan tanggal 18 Agustus 2023 untuk perkuliahan september 2023. 3.Apabila terdapat kekurangan pembayaran Dana Pendidikan Program Perubahan, maka pelamar bersedia membayar kekurangan Dana Pendidikan tersebut, yang jadwal dan kapasitasnya ditentukan oleh BINUS UNIVERSITY.\"   Cara mengajukan pemindahan lokasi kampus mahasiswa adalah dengan cara mengirimkan email permohonan pindah lokasi kampus ke infobinus@binus.edu akan diberikan formulir pindah lokasi kampus setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.    Syarat mengajukan pindah lokasi kuliah oleh mahasiswa adalah dengan mengisi formulir pindah lokasi kampus dan mendapat persetujuan dari kampus sebelumnya.    Mahasiswa dapat memilih lebih dari 1 program studi di Binus dengan cara memilih lebih dari satu program dengan melakukan dua kali pembayaran pendaftaran sekaligus.  \"Calon Mahasiswa yang mengambil single degree dapat lulus dengan 1 gelar saja, Calon Mahasiswa yang mengambil Double Program dapat lulus dengan mendapatkan 2 gelar (S1+S1) sekaligus dalam waktu 4 tahun, dan Calon Mahasiswa yang mengambil program Master Track dapat lulus dengan mendapatkan 2 gelar (S1+S2) sekaligus dalam waktu 5 tahun.\" \"Syarat Pendidikan terbagi menjadi 2 yaitu yang pertama SMA (IPA)/SMK (jurusan tertentu dapat dilihat di https://binus.ac.id/persyaratan-smk/) untuk Sekolah Ilmu Komputer dan Fakultas Teknik, sedangkan SMTA/SMK Sederajat (semua jurusan) untuk Fakultas Desain, Fakultas Sistem Informasi, Program Sarjana Fakultas Bisnis, Fakultas Akuntansi, Fakultas Komunikasi Digital dan Hotel & Pariwisata, dan Fakultas Humaniora\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/faq.csv', sep=\";\", converters={'paragraph': literal_eval})\n",
    "# print(df.head())\n",
    "paragraf = df['paragraphs']\n",
    "judul = df['title']\n",
    "nomor = df['No']\n",
    "data = df['paragraphs']\n",
    "data = \" \".join(data)\n",
    "data = data.replace(\"'\", \"\")\n",
    "print(paragraf)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, datasets):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    question = tss.google(question, to_language='en')\n",
    "\n",
    "    # for text in datasets:\n",
    "    # print(text)\n",
    "    text_string = tss.google(datasets, to_language='en')       \n",
    "    # print(text_string)\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, text_string)\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example through the model.\n",
    "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
    "                    return_dict=True) \n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "    # print(\"Start scoress\", start_scores)\n",
    "    # print(\"End scoress\", end_scores)\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "    # print(\"Answer Start Score\", answer_start)\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "    answer = tss.google(answer, to_language='id')\n",
    "\n",
    "    for key, value in paragraf.items():\n",
    "        if value.find(answer) != -1:\n",
    "            print(f\"The key of the answer is: {key}\")\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 497 tokens.\n",
      "\n",
      "Answer: \"Rp 3, 000, 000\"\n"
     ]
    }
   ],
   "source": [
    "question = \"berapa biaya administrasi untuk melakukan pemindahan program?\"\n",
    "\n",
    "answer_question(question, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b617312d2c3887d7f9c2e1918c61ee9ea67a8670d4cc70f9064140e63cbf8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
