{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Pre-Trained Model for BERT (Load Fine-Tuned BERT-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Andaf/bert-uncased-finetuned-squad-indonesian does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForQuestionAnswering\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mAndaf/bert-uncased-finetuned-squad-indonesian\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m AutoModelForQuestionAnswering\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mAndaf/bert-uncased-finetuned-squad-indonesian\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\auto\\auto_factory.py:463\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    462\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    464\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    465\u001b[0m     )\n\u001b[0;32m    466\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    467\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:2170\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2164\u001b[0m has_file_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m   2165\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrevision\u001b[39m\u001b[39m\"\u001b[39m: revision,\n\u001b[0;32m   2166\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mproxies\u001b[39m\u001b[39m\"\u001b[39m: proxies,\n\u001b[0;32m   2167\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muse_auth_token\u001b[39m\u001b[39m\"\u001b[39m: use_auth_token,\n\u001b[0;32m   2168\u001b[0m }\n\u001b[0;32m   2169\u001b[0m \u001b[39mif\u001b[39;00m has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhas_file_kwargs):\n\u001b[1;32m-> 2170\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2171\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2172\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m but there is a file for TensorFlow weights. Use `from_tf=True` to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m load this model from those weights.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2174\u001b[0m     )\n\u001b[0;32m   2175\u001b[0m \u001b[39melif\u001b[39;00m has_file(pretrained_model_name_or_path, FLAX_WEIGHTS_NAME, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhas_file_kwargs):\n\u001b[0;32m   2176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2177\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2178\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_NAME\u001b[39m}\u001b[39;00m\u001b[39m but there is a file for Flax weights. Use `from_flax=True` to load\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2179\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m this model from those weights.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2180\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: Andaf/bert-uncased-finetuned-squad-indonesian does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\", from_tf=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Downloading Pre-Trained Model for BERT (Load Fine-Tuned BERT-large)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state West Java server backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "from ast import literal_eval\n",
    "\n",
    "# Question Translation Library\n",
    "# import translators as ts\n",
    "# import translators.server as tss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     '' Hingga saat ini BINUS masih belum menyedia...\n",
      "1     '' Pengajuan pemindahan program dapat dilakua...\n",
      "2    \"Proses pemindahan program dapat melalui beber...\n",
      "3     '' Cara mengajukan pemindahan lokasi kampus m...\n",
      "4     '' Syarat mengajukan pindah lokasi kuliah ole...\n",
      "5     '' Mahasiswa dapat memilih lebih dari 1 progr...\n",
      "6    \"Calon Mahasiswa yang mengambil single degree ...\n",
      "7    \"Syarat Pendidikan terbagi menjadi 2 yaitu yan...\n",
      "Name: paragraphs, dtype: object\n",
      "  Hingga saat ini BINUS masih belum menyediakan jalur transfer pendaftaran.    Pengajuan pemindahan program dapat dilakuakn dengan cara mengirimkan email permohonan pindah jurusan ke infobinus@binus.edu lalu akan diberikan formulir pindah program, setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.  \"Proses pemindahan program dapat melalui beberapa proses berikut: 1.Proses pindah program akan dikenakan biaya administrasi sebesar Rp 3.000.000 (tiga juta rupiah) apabila: Permohonan pindah program diajukan setelah tanggal 31 Juli 2023 dan/atau. Permohonan pindah program yang dilakukan untuk kedua kalinya dan atas permohonan pindah program sebelumnya telah disetujui oleh BINUS UNIVERSITY. 2.Batas waktu pengajuan permohonan pindah program adalah sampai dengan tanggal 18 Agustus 2023 untuk perkuliahan september 2023. 3.Apabila terdapat kekurangan pembayaran Dana Pendidikan Program Perubahan, maka pelamar bersedia membayar kekurangan Dana Pendidikan tersebut, yang jadwal dan kapasitasnya ditentukan oleh BINUS UNIVERSITY.\"   Cara mengajukan pemindahan lokasi kampus mahasiswa adalah dengan cara mengirimkan email permohonan pindah lokasi kampus ke infobinus@binus.edu akan diberikan formulir pindah lokasi kampus setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.    Syarat mengajukan pindah lokasi kuliah oleh mahasiswa adalah dengan mengisi formulir pindah lokasi kampus dan mendapat persetujuan dari kampus sebelumnya.    Mahasiswa dapat memilih lebih dari 1 program studi di Binus dengan cara memilih lebih dari satu program dengan melakukan dua kali pembayaran pendaftaran sekaligus.  \"Calon Mahasiswa yang mengambil single degree dapat lulus dengan 1 gelar saja, Calon Mahasiswa yang mengambil Double Program dapat lulus dengan mendapatkan 2 gelar (S1+S1) sekaligus dalam waktu 4 tahun, dan Calon Mahasiswa yang mengambil program Master Track dapat lulus dengan mendapatkan 2 gelar (S1+S2) sekaligus dalam waktu 5 tahun.\" \"Syarat Pendidikan terbagi menjadi 2 yaitu yang pertama SMA (IPA)/SMK (jurusan tertentu dapat dilihat di https://binus.ac.id/persyaratan-smk/) untuk Sekolah Ilmu Komputer dan Fakultas Teknik, sedangkan SMTA/SMK Sederajat (semua jurusan) untuk Fakultas Desain, Fakultas Sistem Informasi, Program Sarjana Fakultas Bisnis, Fakultas Akuntansi, Fakultas Komunikasi Digital dan Hotel & Pariwisata, dan Fakultas Humaniora\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/faq.csv', sep=\";\", converters={'paragraph': literal_eval})\n",
    "# print(df.head())\n",
    "paragraf = df['paragraphs']\n",
    "judul = df['title']\n",
    "nomor = df['No']\n",
    "data = df['paragraphs']\n",
    "data = \" \".join(data)\n",
    "data = data.replace(\"'\", \"\")\n",
    "print(paragraf)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, datasets):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, datasets)\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example through the model.\n",
    "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
    "                    return_dict=True) \n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "    # print(\"Start scoress\", start_scores)\n",
    "    # print(\"End scoress\", end_scores)\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "    # print(\"Answer Start Score\", answer_start)\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "    answer = tss.google(answer, to_language='id')\n",
    "\n",
    "    for key, value in paragraf.items():\n",
    "        if value.find(answer) != -1:\n",
    "            print(f\"The key of the answer is: {key}\")\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 429 tokens.\n",
      "\n",
      "Answer: \"formulir yang sudah kalian isi bisa di scan dan kirimkan kembali . syarat mengajukan pindah lokasi kuliah oleh mahasiswa adalah dengan mengisi formulir pindah lokasi kampus dan mendapat persetujuan dari kampus sebelumnya . mahasiswa dapat memilih lebih dari 1 program studi di binus dengan cara memilih lebih dari satu program dengan melakukan dua kali pembayaran pendaftaran sekaligus . \" calon mahasiswa yang mengambil single degree dapat lulus dengan 1 gelar saja , calon mahasiswa yang mengambil double program dapat lulus dengan mendapatkan 2 gelar ( s1 + s1 ) sekaligus dalam waktu 4 tahun , dan calon mahasiswa yang mengambil program master track dapat lulus dengan mendapatkan 2 gelar ( s1 + s2 ) sekaligus dalam waktu 5 tahun . \" \" syarat pendidikan terbagi menjadi 2 yaitu yang pertama sma ( ipa ) / smk ( jurusan tertentu dapat dilihat di https : / / binus . ac . id / persyaratan - smk / ) untuk sekolah ilmu komputer dan fakultas teknik , sedangkan smta / smk sederajat ( semua jurusan ) untuk fakultas desain , fakultas sistem informasi , program sarjana fakultas bisnis , fakultas akuntansi , fakultas komunikasi digital\"\n"
     ]
    }
   ],
   "source": [
    "question = \"Apa saja syarat pendidikan untuk semua program kuliah?\"\n",
    "\n",
    "answer_question(question, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b617312d2c3887d7f9c2e1918c61ee9ea67a8670d4cc70f9064140e63cbf8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
