{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Resi Sujiwo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All TF 2.0 model weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"Andaf/bert-uncased-finetuned-squad-indonesian\", from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state West Java server backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "from ast import literal_eval\n",
    "\n",
    "# Question Translation Library\n",
    "import translators as ts\n",
    "import translators.server as tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     '' Hingga saat ini BINUS masih belum menyedia...\n",
      "1     '' Pengajuan pemindahan program dapat dilakua...\n",
      "2    \"Proses pemindahan program dapat melalui beber...\n",
      "3     '' Cara mengajukan pemindahan lokasi kampus m...\n",
      "4     '' Syarat mengajukan pindah lokasi kuliah ole...\n",
      "5     '' Mahasiswa dapat memilih lebih dari 1 progr...\n",
      "6    \"Calon Mahasiswa yang mengambil single degree ...\n",
      "7    \"Syarat Pendidikan terbagi menjadi 2 yaitu yan...\n",
      "Name: paragraphs, dtype: object\n",
      "  Hingga saat ini BINUS masih belum menyediakan jalur transfer pendaftaran.    Pengajuan pemindahan program dapat dilakuakn dengan cara mengirimkan email permohonan pindah jurusan ke infobinus@binus.edu lalu akan diberikan formulir pindah program, setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.  \"Proses pemindahan program dapat melalui beberapa proses berikut: 1.Proses pindah program akan dikenakan biaya administrasi sebesar Rp 3.000.000 (tiga juta rupiah) apabila: Permohonan pindah program diajukan setelah tanggal 31 Juli 2023 dan/atau. Permohonan pindah program yang dilakukan untuk kedua kalinya dan atas permohonan pindah program sebelumnya telah disetujui oleh BINUS UNIVERSITY. 2.Batas waktu pengajuan permohonan pindah program adalah sampai dengan tanggal 18 Agustus 2023 untuk perkuliahan september 2023. 3.Apabila terdapat kekurangan pembayaran Dana Pendidikan Program Perubahan, maka pelamar bersedia membayar kekurangan Dana Pendidikan tersebut, yang jadwal dan kapasitasnya ditentukan oleh BINUS UNIVERSITY.\"   Cara mengajukan pemindahan lokasi kampus mahasiswa adalah dengan cara mengirimkan email permohonan pindah lokasi kampus ke infobinus@binus.edu akan diberikan formulir pindah lokasi kampus setelah itu formulir yang sudah kalian isi bisa di scan dan kirimkan kembali.    Syarat mengajukan pindah lokasi kuliah oleh mahasiswa adalah dengan mengisi formulir pindah lokasi kampus dan mendapat persetujuan dari kampus sebelumnya.    Mahasiswa dapat memilih lebih dari 1 program studi di Binus dengan cara memilih lebih dari satu program dengan melakukan dua kali pembayaran pendaftaran sekaligus.  \"Calon Mahasiswa yang mengambil single degree dapat lulus dengan 1 gelar saja, Calon Mahasiswa yang mengambil Double Program dapat lulus dengan mendapatkan 2 gelar (S1+S1) sekaligus dalam waktu 4 tahun, dan Calon Mahasiswa yang mengambil program Master Track dapat lulus dengan mendapatkan 2 gelar (S1+S2) sekaligus dalam waktu 5 tahun.\" \"Syarat Pendidikan terbagi menjadi 2 yaitu yang pertama SMA (IPA)/SMK (jurusan tertentu dapat dilihat di https://binus.ac.id/persyaratan-smk/) untuk Sekolah Ilmu Komputer dan Fakultas Teknik, sedangkan SMTA/SMK Sederajat (semua jurusan) untuk Fakultas Desain, Fakultas Sistem Informasi, Program Sarjana Fakultas Bisnis, Fakultas Akuntansi, Fakultas Komunikasi Digital dan Hotel & Pariwisata, dan Fakultas Humaniora\"\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/faq.csv', sep=\";\", converters={'paragraph': literal_eval})\n",
    "# print(df.head())\n",
    "paragraf = df['paragraphs']\n",
    "judul = df['title']\n",
    "nomor = df['No']\n",
    "data = df['paragraphs']\n",
    "data = \" \".join(data)\n",
    "data = data.replace(\"'\", \"\")\n",
    "print(paragraf)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text)\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids]),\n",
    "                                    return_dict=True) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    print(start_scores, end_scores)\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 429 tokens.\n",
      "\n",
      "start_logits end_logits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mApa saja syarat pendidikan untuk semua program kuliah?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m answer_question(question, data)\n",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m, in \u001b[0;36manswer_question\u001b[1;34m(question, answer_text)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m# ======== Reconstruct Answer ========\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m# Find the tokens with the highest `start` and `end` scores.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(start_scores, end_scores)\n\u001b[1;32m---> 39\u001b[0m answer_start \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(start_scores)\n\u001b[0;32m     40\u001b[0m answer_end \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(end_scores)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Get the string versions of the input tokens.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "question = \"Apa saja syarat pendidikan untuk semua program kuliah?\"\n",
    "\n",
    "\n",
    "answer_question(question, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b617312d2c3887d7f9c2e1918c61ee9ea67a8670d4cc70f9064140e63cbf8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
